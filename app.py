
import streamlit as st
import pandas as pd
import pickle
import re

# -----------------------------
# ЁЯзй Load the trained model
# -----------------------------
with open('NepaliLogisticRegression.pickle', 'rb') as f:
    model = pickle.load(f)

st.title("ЁЯУ░ Nepali News Topic Classifier")
st.write("рдпрд╣рд╛рдБ рдХреБрдиреИ рдкрдирд┐ рдиреЗрдкрд╛рд▓реА рд╕рдорд╛рдЪрд╛рд░ рдЯрд╛рдЗрдк рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдо рдпрд╕рд▓реЗ рдХреБрди рд╡рд┐рд╖рдпрд╕рдБрдЧ рд╕рдореНрдмрдиреНрдзрд┐рдд рдЫ рднрдиреЗрд░ рдЕрдиреБрдорд╛рди рдЧрд░реНрдЫреБред")

# -----------------------------
# ЁЯз╣ Preprocessing Function
# -----------------------------
# Make sure this matches the same function used during training
stopwords = [
    'рдЫ', 'рдЫрдиреН', 'рдерд┐рдП', 'рдЧрд░реЗ', 'рдЧрд░реНрдиреБ', 'рдЧрд░реЗрдХреЛ', 'рдЧрд░реНрдЫ', 'рдЧрд░реНрди', 'рдкрдирд┐',
    'рднрдПрдХреЛ', 'рднрдП', 'рд╣реЛ', 'рд░', 'рд▓рд╛рдИ', 'рдорд╛', 'рдмрд╛рдЯ', 'рд╕рдВрдЧ', 'рдХрд┐', 'рддрдерд╛'
]
suffixes = ['рд╣рд░реБ', 'рд╣рд░реВ', 'рдХреЛ', 'рд▓реЗ', 'рдорд╛', 'рдмрд╛рдЯ', 'рдХрд╛', 'рдХреА', 'рд╣реЛ', 'рдЧрд░реЗрдХреЛ', 'рдЧрд░реЗ', 'рдЧрд░реНрдиреЗ', 'рдЧрд░реНрдЫ']

def clean_and_stem(text):
    text = str(text)
    text = re.sub(r'[A-Za-z0-9]', '', text)
    text = re.sub(r'[^\u0900-\u097F\s]', '', text)
    words = text.split()
    # stem suffixes
    for i in range(len(words)):
        for suf in suffixes:
            if words[i].endswith(suf) and len(words[i]) > len(suf) + 1:
                words[i] = words[i][:-len(suf)]
                break
    words = [w for w in words if w not in stopwords]
    return " ".join(words)

# -----------------------------
# ЁЯУЭ User Input
# -----------------------------
text = st.text_area("рдХреГрдкрдпрд╛ рд╕рдорд╛рдЪрд╛рд░ рд▓реЗрдЦреНрдиреБрд╣реЛрд╕реН:", placeholder="рдЙрджрд╛рд╣рд░рдг: рдкреНрд░рдзрд╛рдирдордиреНрддреНрд░реАрд▓реЗ рдирдпрд╛рдБ рдиреАрддрд┐ рдШреЛрд╖рдгрд╛ рдЧрд░реЗ")

if st.button("ЁЯФо рд╡рд┐рд╖рдп рдЕрдиреБрдорд╛рди рдЧрд░реНрдиреБрд╣реЛрд╕реН"):
    if not text.strip():
        st.warning("рдХреГрдкрдпрд╛ рд╕рдорд╛рдЪрд╛рд░ рд▓реЗрдЦреНрдиреБрд╣реЛрд╕реНред")
    else:
        cleaned_text = clean_and_stem(text)
        prediction = model.predict([cleaned_text])[0]

        # Show cleaned text and result
        st.subheader("рд╕рдорд╛рдЪрд╛рд░:")
        st.write(cleaned_text)

        st.subheader("рдЕрдиреБрдорд╛рди рдЧрд░рд┐рдПрдХреЛ рд╡рд┐рд╖рдп:")
        st.success(prediction)

        st.balloons()
